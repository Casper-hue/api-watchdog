"""
åˆ›å»ºçœŸå®ç”¨æˆ·æ¨¡æ‹Ÿæ•°æ®
100%æ¨¡æ‹ŸçœŸå®ç”¨æˆ·ä½¿ç”¨æƒ…å†µï¼Œå®Œå…¨æŒ‰ç…§ç³»ç»Ÿå®é™…æ”¶é›†çš„æ•°æ®ç±»å‹
"""

from app.models import SessionLocal, Request, init_db
from datetime import datetime, timedelta
import uuid
import random

def create_realistic_test_data():
    """åˆ›å»ºçœŸå®ç”¨æˆ·æ¨¡æ‹Ÿæ•°æ®"""
    print("=== å¼€å§‹åˆ›å»ºçœŸå®ç”¨æˆ·æ¨¡æ‹Ÿæ•°æ® ===")
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()
    db = SessionLocal()
    
    # çœŸå®ç”¨æˆ·é¡¹ç›®é…ç½®
    projects = [
        "webapp-production",    # ç”Ÿäº§ç¯å¢ƒWebåº”ç”¨
        "mobile-app-beta",      # ç§»åŠ¨åº”ç”¨æµ‹è¯•ç‰ˆ
        "internal-tools",       # å†…éƒ¨å·¥å…·
        "data-analysis",        # æ•°æ®åˆ†æé¡¹ç›®
        "customer-support"      # å®¢æˆ·æ”¯æŒç³»ç»Ÿ
    ]
    
    # çœŸå®æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒï¼ˆåŸºäºå®é™…APIå®šä»·ï¼‰
    models_pricing = {
        "gpt-4o": {"input": 0.0025, "output": 0.01, "usage_weight": 0.15},      # é«˜è´¨é‡ä»»åŠ¡
        "gpt-4o-mini": {"input": 0.00015, "output": 0.0006, "usage_weight": 0.35}, # æ—¥å¸¸ä»»åŠ¡
        "claude-3-opus": {"input": 0.015, "output": 0.075, "usage_weight": 0.05},  # å¤æ‚åˆ†æ
        "claude-3-sonnet": {"input": 0.003, "output": 0.015, "usage_weight": 0.25}, # ä¸­ç­‰ä»»åŠ¡
        "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015, "usage_weight": 0.20}  # ç®€å•ä»»åŠ¡
    }
    
    # é¡¹ç›®ä½¿ç”¨æ¨¡å¼é…ç½®
    project_patterns = {
        "webapp-production": {
            "models": ["gpt-4o", "gpt-4o-mini", "claude-3-sonnet"],
            "daily_requests": (50, 150),  # ç”Ÿäº§ç¯å¢ƒè¯·æ±‚é‡è¾ƒå¤§
            "prompt_length": (500, 2000), # è¾ƒé•¿çš„æç¤º
            "token_ratio": 0.3,           # è¾“å‡º/è¾“å…¥tokenæ¯”ä¾‹
            "similarity_threshold": 0.7   # ä¸­ç­‰ç›¸ä¼¼åº¦æ£€æµ‹
        },
        "mobile-app-beta": {
            "models": ["gpt-4o-mini", "gpt-3.5-turbo"],
            "daily_requests": (20, 80),
            "prompt_length": (100, 800),
            "token_ratio": 0.5,
            "similarity_threshold": 0.8
        },
        "internal-tools": {
            "models": ["claude-3-sonnet", "gpt-4o"],
            "daily_requests": (10, 40),
            "prompt_length": (300, 1500),
            "token_ratio": 0.4,
            "similarity_threshold": 0.6
        },
        "data-analysis": {
            "models": ["claude-3-opus", "gpt-4o"],
            "daily_requests": (5, 25),
            "prompt_length": (1000, 5000),
            "token_ratio": 0.2,
            "similarity_threshold": 0.75
        },
        "customer-support": {
            "models": ["gpt-4o-mini", "gpt-3.5-turbo"],
            "daily_requests": (30, 100),
            "prompt_length": (200, 1000),
            "token_ratio": 0.6,
            "similarity_threshold": 0.85
        }
    }
    
    # ç”Ÿæˆè¿‡å»30å¤©çš„æ•°æ®ï¼ˆæ›´çœŸå®çš„æ—¶é—´è·¨åº¦ï¼‰
    base_date = datetime.utcnow()
    total_requests = 0
    
    for day in range(30, -1, -1):
        date = base_date - timedelta(days=day)
        
        for project_id, pattern in project_patterns.items():
            # æ¯å¤©è¯·æ±‚é‡æœ‰æ³¢åŠ¨ï¼ˆå‘¨æœ«è¾ƒå°‘ï¼‰
            weekday = date.weekday()  # 0=Monday, 6=Sunday
            weekend_factor = 0.6 if weekday >= 5 else 1.0  # å‘¨æœ«å‡å°‘40%
            
            daily_min, daily_max = pattern["daily_requests"]
            daily_requests = int(random.randint(daily_min, daily_max) * weekend_factor)
            
            for i in range(daily_requests):
                # éšæœºé€‰æ‹©æ¨¡å‹ï¼ˆåŸºäºä½¿ç”¨æƒé‡ï¼‰
                model_choices = []
                model_weights = []
                for model in pattern["models"]:
                    model_choices.append(model)
                    model_weights.append(models_pricing[model]["usage_weight"])
                
                model = random.choices(model_choices, weights=model_weights)[0]
                pricing = models_pricing[model]
                
                # ç”ŸæˆçœŸå®çš„tokenæ•°é‡
                prompt_min, prompt_max = pattern["prompt_length"]
                prompt_tokens = random.randint(prompt_min, prompt_max)
                completion_tokens = int(prompt_tokens * pattern["token_ratio"] * random.uniform(0.8, 1.2))
                
                # è®¡ç®—çœŸå®æˆæœ¬
                cost = (prompt_tokens * pricing["input"] / 1000) + (completion_tokens * pricing["output"] / 1000)
                
                # ç”Ÿæˆæ—¶é—´æˆ³ï¼ˆåœ¨å½“å¤©å†…éšæœºåˆ†å¸ƒï¼Œå·¥ä½œæ—¶é—´æ›´é›†ä¸­ï¼‰
                if weekday < 5:  # å·¥ä½œæ—¥
                    hour = random.choices(
                        [9,10,11,12,13,14,15,16,17,18,19,20],
                        weights=[2,4,6,3,4,6,8,7,5,3,2,1]
                    )[0]
                else:  # å‘¨æœ«
                    hour = random.choices(
                        [10,11,12,13,14,15,16,17,18,19,20,21],
                        weights=[1,2,3,2,3,4,3,2,2,1,1,1]
                    )[0]
                
                minute = random.randint(0, 59)
                timestamp = date.replace(hour=hour, minute=minute, second=0, microsecond=0)
                
                # ç”Ÿæˆç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆåŸºäºé¡¹ç›®æ¨¡å¼ï¼‰
                similarity_score = random.uniform(0.1, pattern["similarity_threshold"])
                
                # ç”Ÿæˆæ¨¡å¼è¯†åˆ«åˆ†æ•°ï¼ˆåŸºäºä½¿ç”¨æƒ…å†µï¼‰
                pattern_score = random.randint(0, 5)
                
                # ç”Ÿæˆé¡¾é—®çº§åˆ«ï¼ˆåŸºäºç›¸ä¼¼åº¦å’Œæ¨¡å¼åˆ†æ•°ï¼‰
                advisor_level = 0
                if similarity_score > 0.8:
                    advisor_level = 3
                elif similarity_score > 0.6:
                    advisor_level = 2
                elif similarity_score > 0.4:
                    advisor_level = 1
                
                # ç”Ÿæˆè¿›åº¦æŒ‡ç¤ºå™¨
                progress_options = ["exploring", "refining", "resolved", "stuck"]
                progress_weights = [0.4, 0.3, 0.2, 0.1]  # æ¢ç´¢å’Œä¼˜åŒ–æ›´å¸¸è§
                progress_indicator = random.choices(progress_options, weights=progress_weights)[0]
                
                # è®¡ç®—tokenæ•ˆç‡
                token_efficiency = completion_tokens / prompt_tokens if prompt_tokens > 0 else 0
                
                # åˆ›å»ºè¯·æ±‚è®°å½•ï¼ˆ100%çœŸå®æ•°æ®æ ¼å¼ï¼‰
                request = Request(
                    id=str(uuid.uuid4()),
                    timestamp=timestamp,
                    project_id=project_id,
                    provider="openai" if "gpt" in model else "anthropic",
                    model=model,
                    prompt_tokens=prompt_tokens,
                    completion_tokens=completion_tokens,
                    total_cost_usd=round(cost, 6),
                    similarity_score=round(similarity_score, 3),
                    pattern_score=pattern_score,
                    advisor_level=advisor_level,
                    prompt_text=f"ç”¨æˆ·è¯·æ±‚ - é¡¹ç›®: {project_id}, æ—¶é—´: {timestamp.strftime('%Y-%m-%d %H:%M')}",
                    progress_indicator=progress_indicator,
                    token_efficiency=round(token_efficiency, 3)
                )
                
                db.add(request)
                total_requests += 1
    
    # æäº¤åˆ°æ•°æ®åº“
    db.commit()
    db.close()
    
    print(f"âœ… æˆåŠŸåˆ›å»º {total_requests} æ¡çœŸå®ç”¨æˆ·æ¨¡æ‹Ÿè®°å½•")
    print("=== æ•°æ®ç»Ÿè®¡ ===")
    
    # éªŒè¯æ•°æ®
    db = SessionLocal()
    
    # ç»Ÿè®¡æ€»è®°å½•æ•°
    total_count = db.query(Request).count()
    print(f"æ€»è®°å½•æ•°: {total_count}")
    
    # ç»Ÿè®¡é¡¹ç›®åˆ†å¸ƒ
    projects_count = db.query(Request.project_id).distinct().count()
    print(f"é¡¹ç›®æ•°é‡: {projects_count}")
    
    # ç»Ÿè®¡æ¨¡å‹åˆ†å¸ƒ
    models_count = db.query(Request.model).distinct().count()
    print(f"æ¨¡å‹æ•°é‡: {models_count}")
    
    # ç»Ÿè®¡æ—¶é—´èŒƒå›´
    oldest_record = db.query(Request).order_by(Request.timestamp.asc()).first()
    newest_record = db.query(Request).order_by(Request.timestamp.desc()).first()
    print(f"æ•°æ®æ—¶é—´èŒƒå›´: {oldest_record.timestamp.date()} åˆ° {newest_record.timestamp.date()}")
    
    # ç»Ÿè®¡æ€»æˆæœ¬
    total_cost = db.query(Request.total_cost_usd).all()
    total_cost_sum = sum([cost[0] for cost in total_cost])
    print(f"æ€»æˆæœ¬: ${total_cost_sum:.4f}")
    
    # æ˜¾ç¤ºå„é¡¹ç›®ç»Ÿè®¡
    print("\\n=== å„é¡¹ç›®ç»Ÿè®¡ ===")
    for project in projects:
        project_requests = db.query(Request).filter(Request.project_id == project).count()
        project_cost = sum([req[0] for req in db.query(Request.total_cost_usd).filter(Request.project_id == project).all()])
        print(f"{project}: {project_requests} æ¡è®°å½•, æˆæœ¬: ${project_cost:.4f}")
    
    # æ˜¾ç¤ºæ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
    print("\\n=== æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡ ===")
    for model in models_pricing.keys():
        model_requests = db.query(Request).filter(Request.model == model).count()
        model_cost = sum([req[0] for req in db.query(Request.total_cost_usd).filter(Request.model == model).all()])
        if model_requests > 0:
            avg_cost = model_cost / model_requests
            print(f"{model}: {model_requests} æ¬¡ä½¿ç”¨, æ€»æˆæœ¬: ${model_cost:.4f}, å¹³å‡æˆæœ¬: ${avg_cost:.4f}")
    
    db.close()
    
    print("\\n=== çœŸå®ç”¨æˆ·æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå®Œæˆ ===")
    print("âœ… æ•°æ®å®Œå…¨æ¨¡æ‹ŸçœŸå®ç”¨æˆ·ä½¿ç”¨æƒ…å†µ")
    print("ğŸ“Š ç°åœ¨å¯ä»¥æµ‹è¯•ç³»ç»Ÿçš„ç»Ÿè®¡å’Œåˆ†æåŠŸèƒ½")
    print("ğŸ” æ£€æŸ¥dashboardã€statisticsã€projectsé¡µé¢çš„æ˜¾ç¤ºæ•ˆæœ")

if __name__ == "__main__":
    create_realistic_test_data()